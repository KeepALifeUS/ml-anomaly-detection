"""
ðŸŽ¯ Local Outlier Factor (LOF) Anomaly Detector

Implements LOF algorithm for density-based anomaly detection.
Identifies anomalies based on local density deviation compared to neighbors.

Context7 Features:
- Density-based anomaly scoring
- k-nearest neighbors optimization
- Real-time local density computation
- Enterprise monitoring integration
"""

import numpy as np
import pandas as pd
from typing import Union, List, Tuple, Optional, Dict, Any
from dataclasses import dataclass
import structlog
from sklearn.neighbors import LocalOutlierFactor
from sklearn.preprocessing import StandardScaler, RobustScaler
import joblib
import warnings

logger = structlog.get_logger(__name__)

@dataclass
class LOFConfig:
    """Configuration for LOF detector."""
    n_neighbors: int = 20
    algorithm: str = 'auto'  # 'ball_tree', 'kd_tree', 'brute', 'auto'
    leaf_size: int = 30
    metric: str = 'minkowski'
    p: int = 2  # Parameter for minkowski metric
    contamination: float = 0.1
    novelty: bool = True  # True for new data detection
    n_jobs: int = -1
    
    # Context7 enterprise features
    auto_k_optimization: bool = True  # Auto-optimize k
    scaler_type: str = 'robust'
    crypto_optimized: bool = True

class LocalOutlierFactorDetector:
    """
    Local Outlier Factor Anomaly Detector.
    
    Density-based Ð¼ÐµÑ‚Ð¾Ð´ Ð¾Ð±Ð½Ð°Ñ€ÑƒÐ¶ÐµÐ½Ð¸Ñ Ð°Ð½Ð¾Ð¼Ð°Ð»Ð¸Ð¹ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ð¾Ð¹ Ð¿Ð»Ð¾Ñ‚Ð½Ð¾ÑÑ‚Ð¸.
    """
    
    def __init__(self, config: Optional[LOFConfig] = None):
        self.config = config or LOFConfig()
        self.fitted = False
        self.model = None
        self.scaler = None
        self._feature_names = None
        self._optimal_k = None
        
        self._create_scaler()
        
        logger.info(
            "LocalOutlierFactorDetector initialized",
            n_neighbors=self.config.n_neighbors,
            contamination=self.config.contamination,
            metric=self.config.metric
        )
    
    def fit(self, X: Union[np.ndarray, pd.DataFrame], y: Optional[np.ndarray] = None):
        try:
            X, feature_names = self._validate_and_prepare_input(X)
            self._feature_names = feature_names
            
            # ÐœÐ°ÑÑˆÑ‚Ð°Ð±Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ
            if self.scaler is not None:
                X_scaled = self.scaler.fit_transform(X)
            else:
                X_scaled = X
            
            # Auto-optimize k ÐµÑÐ»Ð¸ Ð²ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¾
            if self.config.auto_k_optimization:
                self._optimize_k(X_scaled)
            
            # Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð¸ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸
            self.model = LocalOutlierFactor(
                n_neighbors=self._optimal_k or self.config.n_neighbors,
                algorithm=self.config.algorithm,
                leaf_size=self.config.leaf_size,
                metric=self.config.metric,
                p=self.config.p,
                contamination=self.config.contamination,
                novelty=self.config.novelty,
                n_jobs=self.config.n_jobs
            )
            
            self.model.fit(X_scaled)
            self.fitted = True
            
            logger.info(
                "LOF detector fitted successfully",
                n_samples=len(X),
                n_features=X.shape[1],
                optimal_k=self._optimal_k or self.config.n_neighbors
            )
            
            return self
            
        except Exception as e:
            logger.error("Failed to fit LOF detector", error=str(e))
            raise
    
    def detect(self, X: Union[np.ndarray, pd.DataFrame]) -> Tuple[np.ndarray, np.ndarray]:
        if not self.fitted:
            raise ValueError("Detector must be fitted")
        
        try:
            X, _ = self._validate_and_prepare_input(X)
            
            if self.scaler is not None:
                X_scaled = self.scaler.transform(X)
            else:
                X_scaled = X
            
            # ÐŸÑ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ðµ Ð°Ð½Ð¾Ð¼Ð°Ð»Ð¸Ð¹
            if self.config.novelty:
                predictions = self.model.predict(X_scaled)
                scores = -self.model.decision_function(X_scaled)
            else:
                # Ð”Ð»Ñ Ð¾Ð±ÑƒÑ‡Ð°ÑŽÑ‰Ð¸Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ negative_outlier_factor_
                predictions = self.model.fit_predict(X_scaled)
                scores = -self.model.negative_outlier_factor_
            
            anomaly_labels = np.where(predictions == -1, 1, 0)
            
            logger.debug(
                "LOF detection completed",
                n_samples=len(X),
                n_anomalies=np.sum(anomaly_labels),
                max_score=np.max(scores)
            )
            
            return anomaly_labels, scores
            
        except Exception as e:
            logger.error("Failed LOF detection", error=str(e))
            raise
    
    def detect_realtime(self, value: Union[float, np.ndarray]) -> Tuple[bool, float]:
        if not self.fitted:
            raise ValueError("Detector must be fitted")
        
        try:
            if isinstance(value, (int, float)):
                value = np.array([value])
            elif isinstance(value, list):
                value = np.array(value)
            
            value = value.reshape(1, -1)
            
            if self.scaler is not None:
                value_scaled = self.scaler.transform(value)
            else:
                value_scaled = value
            
            prediction = self.model.predict(value_scaled)[0]
            score = -self.model.decision_function(value_scaled)[0]
            
            is_anomaly = prediction == -1
            
            return is_anomaly, score
            
        except Exception as e:
            logger.error("Failed real-time LOF detection", error=str(e))
            raise
    
    def _validate_and_prepare_input(self, X):
        feature_names = None
        
        if isinstance(X, pd.DataFrame):
            feature_names = X.columns.tolist()
            X = X.values
        elif isinstance(X, pd.Series):
            feature_names = [X.name] if X.name else ["feature_0"]
            X = X.values.reshape(-1, 1)
        elif isinstance(X, list):
            X = np.array(X)
        
        if X.ndim == 1:
            X = X.reshape(-1, 1)
        
        if np.any(~np.isfinite(X)):
            warnings.warn("Input contains NaN or Inf values, replacing with median")
            from sklearn.impute import SimpleImputer
            imputer = SimpleImputer(strategy='median')
            X = imputer.fit_transform(X)
        
        return X, feature_names
    
    def _create_scaler(self):
        if self.config.scaler_type == 'standard':
            self.scaler = StandardScaler()
        elif self.config.scaler_type == 'robust':
            self.scaler = RobustScaler()
        else:
            self.scaler = None
    
    def _optimize_k(self, X):
        """ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ°Ñ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð° k."""
        n_samples = X.shape[0]
        
        # Ð”Ð¸Ð°Ð¿Ð°Ð·Ð¾Ð½ k Ð´Ð»Ñ Ñ‚ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ
        k_min = max(5, int(np.sqrt(n_samples) / 2))
        k_max = min(50, n_samples // 10)
        k_candidates = range(k_min, k_max, 2)
        
        best_k = self.config.n_neighbors
        best_score = float('-inf')
        
        for k in k_candidates:
            try:
                temp_model = LocalOutlierFactor(
                    n_neighbors=k,
                    contamination=self.config.contamination,
                    novelty=False  # Ð”Ð»Ñ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ð¸ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ð¾Ð±ÑƒÑ‡Ð°ÑŽÑ‰Ð¸Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ
                )
                
                temp_model.fit(X)
                # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ ÑÑ€ÐµÐ´Ð½ÐµÐµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ LOF ÐºÐ°Ðº Ð¼ÐµÑ‚Ñ€Ð¸ÐºÑƒ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð°
                avg_lof = np.mean(temp_model.negative_outlier_factor_)
                
                if avg_lof > best_score:
                    best_score = avg_lof
                    best_k = k
                    
            except Exception:
                continue
        
        self._optimal_k = best_k
        
        logger.info(
            "Optimized k parameter for LOF",
            original_k=self.config.n_neighbors,
            optimal_k=self._optimal_k,
            tested_range=(k_min, k_max)
        )
    
    def get_statistics(self) -> Dict[str, Any]:
        if not self.fitted:
            return {"status": "not_fitted"}
        
        return {
            "fitted": True,
            "n_neighbors": self._optimal_k or self.config.n_neighbors,
            "contamination": self.config.contamination,
            "metric": self.config.metric,
            "feature_names": self._feature_names
        }

def create_crypto_lof_detector(price_data: pd.DataFrame, features: Optional[List[str]] = None) -> LocalOutlierFactorDetector:
    if features is None:
        features = ['close', 'volume']
        if 'returns' in price_data.columns:
            features.append('returns')
    
    config = LOFConfig(
        n_neighbors=20,
        contamination=0.05,
        auto_k_optimization=True,
        crypto_optimized=True,
        scaler_type='robust'
    )
    
    detector = LocalOutlierFactorDetector(config)
    detector.fit(price_data[features].dropna())
    
    return detector