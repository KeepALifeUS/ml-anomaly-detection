"""
üß™ Grubbs' Test Anomaly Detector

Implements Grubbs' test for detecting outliers in univariate normal distributions.
This is a statistical test that identifies single outliers in a dataset.

Test statistic: G = max|Xi - XÃÑ| / s
Where XÃÑ is the sample mean and s is the sample standard deviation.

Context7 Features:
- Statistical significance testing
- Single outlier detection
- Normal distribution assumption
- Iterative outlier removal
"""

import numpy as np
import pandas as pd
from typing import Union, List, Tuple, Optional, Dict, Any
from dataclasses import dataclass
import structlog
from scipy import stats
import warnings

logger = structlog.get_logger(__name__)

@dataclass
class GrubbsConfig:
    """Configuration for Grubbs test detector."""
    alpha: float = 0.05  # –£—Ä–æ–≤–µ–Ω—å –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏
    max_outliers: Optional[int] = None  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—ã–±—Ä–æ—Å–æ–≤
    iterative: bool = True  # –ò—Ç–µ—Ä–∞—Ç–∏–≤–Ω–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ –≤—ã–±—Ä–æ—Å–æ–≤
    two_sided: bool = True  # –î–≤—É—Å—Ç–æ—Ä–æ–Ω–Ω–∏–π —Ç–µ—Å—Ç
    min_samples: int = 7  # –ú–∏–Ω–∏–º—É–º –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–π –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏
    normality_check: bool = True  # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–æ—Ä–º–∞–ª—å–Ω–æ—Å—Ç–∏
    normality_alpha: float = 0.01  # –£—Ä–æ–≤–µ–Ω—å –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏ –¥–ª—è —Ç–µ—Å—Ç–∞ –Ω–æ—Ä–º–∞–ª—å–Ω–æ—Å—Ç–∏

class GrubbsTestDetector:
    """
    Grubbs' Test Anomaly Detector.
    
    –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π —Ç–µ—Å—Ç –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –≤—ã–±—Ä–æ—Å–æ–≤ –≤ –Ω–æ—Ä–º–∞–ª—å–Ω–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.
    –ü–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –Ω–µ–±–æ–ª—å—à–∏—Ö –≤—ã–±–æ—Ä–æ–∫ —Å –æ–¥–Ω–∏–º –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –≤—ã–±—Ä–æ—Å–∞–º–∏.
    
    Context7 Features:
    - Statistical rigor
    - Hypothesis testing approach
    - Iterative outlier detection
    - Distribution validation
    """
    
    def __init__(self, config: Optional[GrubbsConfig] = None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Grubbs test –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞.
        
        Args:
            config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞
        """
        self.config = config or GrubbsConfig()
        self.fitted = False
        self._mean = None
        self._std = None
        self._critical_values = {}
        self._normality_pvalue = None
        
        logger.info(
            "GrubbsTestDetector initialized",
            alpha=self.config.alpha,
            two_sided=self.config.two_sided,
            iterative=self.config.iterative
        )
    
    def fit(self, X: Union[np.ndarray, pd.DataFrame, pd.Series]) -> 'GrubbsTestDetector':
        """
        –û–±—É—á–µ–Ω–∏–µ –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞ –Ω–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö.
        
        Args:
            X: –ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
            
        Returns:
            self: –û–±—É—á–µ–Ω–Ω—ã–π –¥–µ—Ç–µ–∫—Ç–æ—Ä
        """
        try:
            X = self._validate_input(X)
            
            if len(X) < self.config.min_samples:
                raise ValueError(
                    f"Insufficient samples for Grubbs test: {len(X)} < {self.config.min_samples}"
                )
            
            # –î–ª—è –º–Ω–æ–≥–æ–º–µ—Ä–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –ø—Ä–∏–º–µ–Ω—è–µ–º –∫ –∫–∞–∂–¥–æ–º—É –ø—Ä–∏–∑–Ω–∞–∫—É –æ—Ç–¥–µ–ª—å–Ω–æ
            if X.shape[1] > 1:
                logger.warning(
                    "Grubbs test is univariate, applying to each feature separately"
                )
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–æ—Ä–º–∞–ª—å–Ω–æ—Å—Ç—å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
            if self.config.normality_check:
                self._check_normality(X)
            
            # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            self._mean = np.mean(X, axis=0)
            self._std = np.std(X, axis=0, ddof=1)
            
            # –ü—Ä–µ–¥–≤—ã—á–∏—Å–ª—è–µ–º –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ä–∞–∑–º–µ—Ä–æ–≤ –≤—ã–±–æ—Ä–∫–∏
            self._precompute_critical_values()
            
            self.fitted = True
            
            logger.info(
                "GrubbsTestDetector fitted successfully",
                n_samples=len(X),
                n_features=X.shape[1] if X.ndim > 1 else 1,
                normality_pvalue=self._normality_pvalue,
                mean=self._mean.tolist() if isinstance(self._mean, np.ndarray) else self._mean,
                std=self._std.tolist() if isinstance(self._std, np.ndarray) else self._std
            )
            
            return self
            
        except Exception as e:
            logger.error("Failed to fit GrubbsTestDetector", error=str(e))
            raise
    
    def detect(self, X: Union[np.ndarray, pd.DataFrame, pd.Series]) -> Tuple[np.ndarray, np.ndarray]:
        """
        –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∞–Ω–æ–º–∞–ª–∏–π —Å –ø–æ–º–æ—â—å—é —Ç–µ—Å—Ç–∞ –ì—Ä–∞–±–±—Å–∞.
        
        Args:
            X: –î–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            
        Returns:
            Tuple[np.ndarray, np.ndarray]: (anomaly_labels, test_statistics)
        """
        if not self.fitted:
            raise ValueError("Detector must be fitted before detecting anomalies")
        
        try:
            X = self._validate_input(X)
            
            if X.shape[1] == 1:
                # –û–¥–Ω–æ–º–µ—Ä–Ω—ã–π —Å–ª—É—á–∞–π
                anomaly_labels, test_stats = self._detect_univariate(X.flatten())
            else:
                # –ú–Ω–æ–≥–æ–º–µ—Ä–Ω—ã–π —Å–ª—É—á–∞–π - –ø—Ä–∏–º–µ–Ω—è–µ–º –∫ –∫–∞–∂–¥–æ–º—É –ø—Ä–∏–∑–Ω–∞–∫—É
                anomaly_labels, test_stats = self._detect_multivariate(X)
            
            logger.debug(
                "Grubbs test completed",
                n_samples=len(X),
                n_anomalies=np.sum(anomaly_labels),
                anomaly_rate=f"{np.mean(anomaly_labels):.3%}",
                max_test_stat=np.max(test_stats)
            )
            
            return anomaly_labels, test_stats
            
        except Exception as e:
            logger.error("Failed to detect anomalies with Grubbs test", error=str(e))
            raise
    
    def detect_single_outlier(self, X: np.ndarray) -> Tuple[bool, int, float, float]:
        """
        –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –æ–¥–Ω–æ–≥–æ –≤—ã–±—Ä–æ—Å–∞ —Å –ø–æ–º–æ—â—å—é —Ç–µ—Å—Ç–∞ –ì—Ä–∞–±–±—Å–∞.
        
        Args:
            X: –û–¥–Ω–æ–º–µ—Ä–Ω—ã–π –º–∞—Å—Å–∏–≤ –¥–∞–Ω–Ω—ã—Ö
            
        Returns:
            Tuple[bool, int, float, float]: (is_outlier, outlier_index, test_statistic, p_value)
        """
        if not self.fitted:
            raise ValueError("Detector must be fitted")
        
        X = X.flatten()
        n = len(X)
        
        if n < self.config.min_samples:
            return False, -1, 0.0, 1.0
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ç–µ—Å—Ç–∞
        mean = np.mean(X)
        std = np.std(X, ddof=1)
        
        if std == 0:
            return False, -1, 0.0, 1.0
        
        # G = max|Xi - XÃÑ| / s
        deviations = np.abs(X - mean)
        max_deviation_idx = np.argmax(deviations)
        test_statistic = deviations[max_deviation_idx] / std
        
        # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
        critical_value = self._get_critical_value(n)
        
        # P-–∑–Ω–∞—á–µ–Ω–∏–µ (–ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ–µ)
        t_stat = test_statistic * np.sqrt((n-2) / (n - 1 - test_statistic**2))
        p_value = 2 * (1 - stats.t.cdf(abs(t_stat), n-2))
        
        is_outlier = test_statistic > critical_value
        
        if is_outlier:
            logger.debug(
                "Grubbs test outlier detected",
                index=max_deviation_idx,
                value=X[max_deviation_idx],
                test_statistic=test_statistic,
                critical_value=critical_value,
                p_value=p_value
            )
        
        return is_outlier, max_deviation_idx, test_statistic, p_value
    
    def _validate_input(self, X: Union[np.ndarray, pd.DataFrame, pd.Series]) -> np.ndarray:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö."""
        if isinstance(X, pd.DataFrame):
            X = X.values
        elif isinstance(X, pd.Series):
            X = X.values.reshape(-1, 1)
        elif isinstance(X, list):
            X = np.array(X)
        
        if X.ndim == 1:
            X = X.reshape(-1, 1)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ NaN –∏ Inf
        if np.any(~np.isfinite(X)):
            warnings.warn("Input contains NaN or Inf values, removing them")
            X = X[np.isfinite(X).all(axis=1)]
        
        return X
    
    def _detect_univariate(self, X: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –≤—ã–±—Ä–æ—Å–æ–≤ –≤ –æ–¥–Ω–æ–º–µ—Ä–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö."""
        X_work = X.copy()
        n_original = len(X)
        anomaly_labels = np.zeros(n_original, dtype=int)
        test_statistics = np.zeros(n_original)
        
        # –°–æ–∑–¥–∞–µ–º –º–∞–ø–ø–∏–Ω–≥ –∏–Ω–¥–µ–∫—Å–æ–≤
        remaining_indices = np.arange(n_original)
        
        max_outliers = self.config.max_outliers or len(X) // 10
        outliers_found = 0
        
        while len(X_work) >= self.config.min_samples and outliers_found < max_outliers:
            is_outlier, local_idx, test_stat, p_value = self.detect_single_outlier(X_work)
            
            if not is_outlier or not self.config.iterative:
                break
            
            # –ù–∞—Ö–æ–¥–∏–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π –∏–Ω–¥–µ–∫—Å
            global_idx = remaining_indices[local_idx]
            
            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            anomaly_labels[global_idx] = 1
            test_statistics[global_idx] = test_stat
            
            # –£–¥–∞–ª—è–µ–º –≤—ã–±—Ä–æ—Å –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–π –∏—Ç–µ—Ä–∞—Ü–∏–∏
            X_work = np.delete(X_work, local_idx)
            remaining_indices = np.delete(remaining_indices, local_idx)
            outliers_found += 1
            
            if not self.config.iterative:
                break
        
        # –î–ª—è –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è —Ç–æ—á–µ–∫ –≤—ã—á–∏—Å–ª—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        if len(X_work) >= self.config.min_samples:
            mean_final = np.mean(X_work)
            std_final = np.std(X_work, ddof=1)
            
            for idx in remaining_indices:
                if std_final > 0:
                    test_statistics[idx] = abs(X[idx] - mean_final) / std_final
        
        return anomaly_labels, test_statistics
    
    def _detect_multivariate(self, X: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –≤—ã–±—Ä–æ—Å–æ–≤ –≤ –º–Ω–æ–≥–æ–º–µ—Ä–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö (–ø–æ –∫–∞–∂–¥–æ–º—É –ø—Ä–∏–∑–Ω–∞–∫—É –æ—Ç–¥–µ–ª—å–Ω–æ)."""
        n_samples, n_features = X.shape
        anomaly_labels = np.zeros(n_samples, dtype=int)
        test_statistics = np.zeros(n_samples)
        
        for feature_idx in range(n_features):
            feature_data = X[:, feature_idx]
            feature_labels, feature_stats = self._detect_univariate(feature_data)
            
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (–∞–Ω–æ–º–∞–ª–∏—è –µ—Å–ª–∏ —Ö–æ—Ç—è –±—ã –≤ –æ–¥–Ω–æ–º –ø—Ä–∏–∑–Ω–∞–∫–µ)
            anomaly_labels = np.maximum(anomaly_labels, feature_labels)
            test_statistics = np.maximum(test_statistics, feature_stats)
        
        return anomaly_labels, test_statistics
    
    def _check_normality(self, X: np.ndarray) -> None:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–æ—Ä–º–∞–ª—å–Ω–æ—Å—Ç–∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è."""
        if X.shape[1] == 1:
            # –û–¥–Ω–æ–º–µ—Ä–Ω—ã–π —Å–ª—É—á–∞–π
            _, p_value = stats.shapiro(X.flatten())
            self._normality_pvalue = p_value
        else:
            # –ú–Ω–æ–≥–æ–º–µ—Ä–Ω—ã–π —Å–ª—É—á–∞–π - –ø—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–π –ø—Ä–∏–∑–Ω–∞–∫
            p_values = []
            for feature_idx in range(X.shape[1]):
                _, p_value = stats.shapiro(X[:, feature_idx])
                p_values.append(p_value)
            self._normality_pvalue = min(p_values)
        
        if self._normality_pvalue < self.config.normality_alpha:
            logger.warning(
                "Data may not be normally distributed",
                shapiro_p_value=self._normality_pvalue,
                threshold=self.config.normality_alpha,
                recommendation="Consider using non-parametric methods"
            )
    
    def _precompute_critical_values(self) -> None:
        """–ü—Ä–µ–¥–≤—ã—á–∏—Å–ª–µ–Ω–∏–µ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ä–∞–∑–º–µ—Ä–æ–≤ –≤—ã–±–æ—Ä–∫–∏."""
        # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è —Ç–µ—Å—Ç–∞ –ì—Ä–∞–±–±—Å–∞ (–ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω—ã–µ)
        alpha = self.config.alpha
        
        for n in range(7, 1001):  # –û—Ç 7 –¥–æ 1000 –Ω–∞–±–ª—é–¥–µ–Ω–∏–π
            # –§–æ—Ä–º—É–ª–∞ –¥–ª—è –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è (–ø—Ä–∏–±–ª–∏–∂–µ–Ω–∏–µ)
            t_critical = stats.t.ppf(1 - alpha/(2*n), n-2)
            g_critical = ((n-1) * np.sqrt(t_critical**2 / (n-2 + t_critical**2))) / np.sqrt(n)
            self._critical_values[n] = g_critical
    
    def _get_critical_value(self, n: int) -> float:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è —Ä–∞–∑–º–µ—Ä–∞ –≤—ã–±–æ—Ä–∫–∏ n."""
        if n in self._critical_values:
            return self._critical_values[n]
        
        # –î–ª—è –±–æ–ª—å—à–∏—Ö –≤—ã–±–æ—Ä–æ–∫ –∏—Å–ø–æ–ª—å–∑—É–µ–º –∞—Å–∏–º–ø—Ç–æ—Ç–∏—á–µ—Å–∫—É—é —Ñ–æ—Ä–º—É–ª—É
        if n > 1000:
            # –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è –±–æ–ª—å—à–∏—Ö n
            z_critical = stats.norm.ppf(1 - self.config.alpha/2)
            return z_critical * np.sqrt((n-1)**2 / (n * (n-2)))
        
        # –í—ã—á–∏—Å–ª—è–µ–º –Ω–∞ –ª–µ—Ç—É –¥–ª—è –Ω–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö —Ä–∞–∑–º–µ—Ä–æ–≤
        alpha = self.config.alpha
        t_critical = stats.t.ppf(1 - alpha/(2*n), n-2)
        g_critical = ((n-1) * np.sqrt(t_critical**2 / (n-2 + t_critical**2))) / np.sqrt(n)
        
        return g_critical
    
    def get_statistics(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫ –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞."""
        if not self.fitted:
            return {"status": "not_fitted"}
        
        return {
            "fitted": True,
            "alpha": self.config.alpha,
            "two_sided": self.config.two_sided,
            "iterative": self.config.iterative,
            "min_samples": self.config.min_samples,
            "normality_pvalue": self._normality_pvalue,
            "mean": self._mean.tolist() if isinstance(self._mean, np.ndarray) else self._mean,
            "std": self._std.tolist() if isinstance(self._std, np.ndarray) else self._std,
            "critical_values_computed": len(self._critical_values)
        }

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –¥–ª—è –∫—Ä–∏–ø—Ç–æ—Ç—Ä–µ–π–¥–∏–Ω–≥–∞
def create_crypto_grubbs_detector(
    price_data: pd.DataFrame,
    feature: str = 'returns',
    alpha: float = 0.05
) -> GrubbsTestDetector:
    """
    –°–æ–∑–¥–∞–Ω–∏–µ Grubbs –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞ –¥–ª—è –∫—Ä–∏–ø—Ç–æ–¥–∞–Ω–Ω—ã—Ö.
    
    Args:
        price_data: DataFrame —Å —Ü–µ–Ω–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
        feature: –ü—Ä–∏–∑–Ω–∞–∫ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ (–ª—É—á—à–µ –≤—Å–µ–≥–æ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å returns)
        alpha: –£—Ä–æ–≤–µ–Ω—å –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏
        
    Returns:
        –ù–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π GrubbsTestDetector
    """
    # –í—ã—á–∏—Å–ª—è–µ–º –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏ –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç
    if 'returns' not in price_data.columns and feature == 'returns':
        price_data = price_data.copy()
        price_data['returns'] = price_data['close'].pct_change().dropna()
    
    config = GrubbsConfig(
        alpha=alpha,
        iterative=True,
        two_sided=True,
        normality_check=True,
        max_outliers=max(1, len(price_data) // 50)  # –ú–∞–∫—Å–∏–º—É–º 2% –≤—ã–±—Ä–æ—Å–æ–≤
    )
    
    detector = GrubbsTestDetector(config)
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω –ø—Ä–∏–∑–Ω–∞–∫ (Grubbs test –æ–¥–Ω–æ–º–µ—Ä–Ω—ã–π)
    if feature in price_data.columns:
        feature_data = price_data[feature].dropna().values.reshape(-1, 1)
        detector.fit(feature_data)
    else:
        raise ValueError(f"Feature '{feature}' not found in price_data")
    
    return detector