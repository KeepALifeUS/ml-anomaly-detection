"""
üéØ Tukey's Fences Anomaly Detector

Implements Tukey's method for outlier detection using fences based on quartiles.
Also known as the "boxplot method" - commonly used for exploratory data analysis.

Fences:
- Inner fences: Q1 - 1.5*IQR, Q3 + 1.5*IQR (mild outliers)
- Outer fences: Q1 - 3.0*IQR, Q3 + 3.0*IQR (extreme outliers)

Context7 Features:
- Two-tier outlier classification
- Visual interpretation support
- Robust quartile-based method
- Configurable fence multipliers
"""

import numpy as np
import pandas as pd
from typing import Union, List, Tuple, Optional, Dict, Any
from dataclasses import dataclass
from enum import Enum
import structlog
import warnings

logger = structlog.get_logger(__name__)

class OutlierSeverity(Enum):
    """–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Å–µ—Ä—å–µ–∑–Ω–æ—Å—Ç–∏ –≤—ã–±—Ä–æ—Å–æ–≤."""
    NORMAL = 0
    MILD = 1      # –ú–µ–∂–¥—É –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–º–∏ –∏ –≤–Ω–µ—à–Ω–∏–º–∏ –≥—Ä–∞–Ω–∏—Ü–∞–º–∏
    EXTREME = 2   # –ó–∞ –ø—Ä–µ–¥–µ–ª–∞–º–∏ –≤–Ω–µ—à–Ω–∏—Ö –≥—Ä–∞–Ω–∏—Ü

@dataclass
class TukeyConfig:
    """Configuration for Tukey's method detector."""
    inner_fence_factor: float = 1.5  # –ú–Ω–æ–∂–∏—Ç–µ–ª—å –¥–ª—è –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö –≥—Ä–∞–Ω–∏—Ü
    outer_fence_factor: float = 3.0  # –ú–Ω–æ–∂–∏—Ç–µ–ª—å –¥–ª—è –≤–Ω–µ—à–Ω–∏—Ö –≥—Ä–∞–Ω–∏—Ü
    classify_severity: bool = True  # –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å —Å–µ—Ä—å–µ–∑–Ω–æ—Å—Ç—å –≤—ã–±—Ä–æ—Å–æ–≤
    bilateral: bool = True  # –î–≤—É—Å—Ç–æ—Ä–æ–Ω–Ω—è—è –ø—Ä–æ–≤–µ—Ä–∫–∞
    quantile_method: str = 'linear'  # –ú–µ—Ç–æ–¥ –∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏–∏ –∫–≤–∞–Ω—Ç–∏–ª–µ–π
    min_samples: int = 5

class TukeyMethodDetector:
    """
    Tukey's Fences Anomaly Detector.
    
    –ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π –º–µ—Ç–æ–¥ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –≤—ã–±—Ä–æ—Å–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–≤–∞—Ä—Ç–∏–ª–µ–π –∏ IQR.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ boxplot'–∞—Ö –∏ —à–∏—Ä–æ–∫–æ –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è –≤ –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–º –∞–Ω–∞–ª–∏–∑–µ –¥–∞–Ω–Ω—ã—Ö.
    
    Context7 Features:
    - Industry standard method
    - Visual interpretation ready
    - Two-tier classification
    - Robust to distribution shape
    """
    
    def __init__(self, config: Optional[TukeyConfig] = None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Tukey's method –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞.
        
        Args:
            config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞
        """
        self.config = config or TukeyConfig()
        self.fitted = False
        self._q1 = None
        self._q3 = None
        self._iqr = None
        self._inner_lower = None
        self._inner_upper = None
        self._outer_lower = None
        self._outer_upper = None
        
        logger.info(
            "TukeyMethodDetector initialized",
            inner_factor=self.config.inner_fence_factor,
            outer_factor=self.config.outer_fence_factor,
            classify_severity=self.config.classify_severity
        )
    
    def fit(self, X: Union[np.ndarray, pd.DataFrame, pd.Series]) -> 'TukeyMethodDetector':
        """
        –û–±—É—á–µ–Ω–∏–µ –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞ –Ω–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö.
        
        Args:
            X: –ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
            
        Returns:
            self: –û–±—É—á–µ–Ω–Ω—ã–π –¥–µ—Ç–µ–∫—Ç–æ—Ä
        """
        try:
            X = self._validate_input(X)
            
            if len(X) < self.config.min_samples:
                raise ValueError(
                    f"Insufficient samples: {len(X)} < {self.config.min_samples}"
                )
            
            # –í—ã—á–∏—Å–ª—è–µ–º –∫–≤–∞—Ä—Ç–∏–ª–∏
            self._q1 = np.percentile(
                X, 25, axis=0, method=self.config.quantile_method
            )
            self._q3 = np.percentile(
                X, 75, axis=0, method=self.config.quantile_method
            )
            
            # –ú–µ–∂–∫–≤–∞—Ä—Ç–∏–ª—å–Ω—ã–π —Ä–∞–∑–º–∞—Ö
            self._iqr = self._q3 - self._q1
            
            # –ó–∞—â–∏—Ç–∞ –æ—Ç –¥–µ–ª–µ–Ω–∏—è –Ω–∞ –Ω–æ–ª—å
            self._iqr = np.where(self._iqr == 0, np.finfo(float).eps, self._iqr)
            
            # –í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ –≥—Ä–∞–Ω–∏—Ü—ã (mild outliers)
            self._inner_lower = self._q1 - self.config.inner_fence_factor * self._iqr
            self._inner_upper = self._q3 + self.config.inner_fence_factor * self._iqr
            
            # –í–Ω–µ—à–Ω–∏–µ –≥—Ä–∞–Ω–∏—Ü—ã (extreme outliers)
            self._outer_lower = self._q1 - self.config.outer_fence_factor * self._iqr
            self._outer_upper = self._q3 + self.config.outer_fence_factor * self._iqr
            
            self.fitted = True
            
            logger.info(
                "TukeyMethodDetector fitted successfully",
                n_samples=len(X),
                n_features=X.shape[1] if X.ndim > 1 else 1,
                q1=self._q1.tolist() if isinstance(self._q1, np.ndarray) else self._q1,
                q3=self._q3.tolist() if isinstance(self._q3, np.ndarray) else self._q3,
                iqr=self._iqr.tolist() if isinstance(self._iqr, np.ndarray) else self._iqr
            )
            
            return self
            
        except Exception as e:
            logger.error("Failed to fit TukeyMethodDetector", error=str(e))
            raise
    
    def detect(self, X: Union[np.ndarray, pd.DataFrame, pd.Series]) -> Tuple[np.ndarray, np.ndarray]:
        """
        –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∞–Ω–æ–º–∞–ª–∏–π –≤ –¥–∞–Ω–Ω—ã—Ö.
        
        Args:
            X: –î–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            
        Returns:
            Tuple[np.ndarray, np.ndarray]: (anomaly_labels, severity_scores)
                anomaly_labels: 0=normal, 1=mild outlier, 2=extreme outlier
                severity_scores: –†–∞—Å—Å—Ç–æ—è–Ω–∏–µ –¥–æ –±–ª–∏–∂–∞–π—à–µ–π –≥—Ä–∞–Ω–∏—Ü—ã (–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ)
        """
        if not self.fitted:
            raise ValueError("Detector must be fitted before detecting anomalies")
        
        try:
            X = self._validate_input(X)
            
            # –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ–º –∞–Ω–æ–º–∞–ª–∏–∏
            anomaly_labels = self._classify_outliers(X)
            
            # –í—ã—á–∏—Å–ª—è–µ–º —Å–µ—Ä—å–µ–∑–Ω–æ—Å—Ç—å (—Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –¥–æ –≥—Ä–∞–Ω–∏—Ü)
            severity_scores = self._calculate_severity_scores(X)
            
            n_mild = np.sum(anomaly_labels == 1)
            n_extreme = np.sum(anomaly_labels == 2)
            n_total_outliers = n_mild + n_extreme
            
            logger.debug(
                "Tukey's method detection completed",
                n_samples=len(X),
                n_mild_outliers=n_mild,
                n_extreme_outliers=n_extreme,
                total_outliers=n_total_outliers,
                outlier_rate=f"{n_total_outliers/len(X):.3%}",
                max_severity=np.max(severity_scores)
            )
            
            return anomaly_labels, severity_scores
            
        except Exception as e:
            logger.error("Failed to detect anomalies with Tukey's method", error=str(e))
            raise
    
    def detect_realtime(self, value: Union[float, np.ndarray]) -> Tuple[int, float]:
        """
        Real-time –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∞–Ω–æ–º–∞–ª–∏–π.
        
        Args:
            value: –ó–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
            
        Returns:
            Tuple[int, float]: (severity_level, severity_score)
                severity_level: 0=normal, 1=mild, 2=extreme
                severity_score: –ß–∏—Å–ª–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞ —Å–µ—Ä—å–µ–∑–Ω–æ—Å—Ç–∏
        """
        if not self.fitted:
            raise ValueError("Detector must be fitted before real-time detection")
        
        try:
            if isinstance(value, (int, float)):
                value = np.array([value])
            elif isinstance(value, list):
                value = np.array(value)
            
            value = value.reshape(1, -1)
            severity_level = self._classify_outliers(value)[0]
            severity_score = self._calculate_severity_scores(value)[0]
            
            if severity_level > 0:
                logger.warning(
                    "Real-time Tukey outlier detected",
                    value=value[0],
                    severity_level=severity_level,
                    severity_score=severity_score,
                    classification=OutlierSeverity(severity_level).name
                )
            
            return int(severity_level), severity_score
            
        except Exception as e:
            logger.error("Failed real-time Tukey detection", error=str(e))
            raise
    
    def _validate_input(self, X: Union[np.ndarray, pd.DataFrame, pd.Series]) -> np.ndarray:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö."""
        if isinstance(X, pd.DataFrame):
            X = X.values
        elif isinstance(X, pd.Series):
            X = X.values.reshape(-1, 1)
        elif isinstance(X, list):
            X = np.array(X)
        
        if X.ndim == 1:
            X = X.reshape(-1, 1)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ NaN –∏ Inf
        if np.any(~np.isfinite(X)):
            warnings.warn("Input contains NaN or Inf values, removing them")
            X = X[np.isfinite(X).all(axis=1)]
        
        return X
    
    def _classify_outliers(self, X: np.ndarray) -> np.ndarray:
        """–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –≤—ã–±—Ä–æ—Å–æ–≤ –ø–æ —É—Ä–æ–≤–Ω—è–º —Å–µ—Ä—å–µ–∑–Ω–æ—Å—Ç–∏."""
        n_samples = len(X)
        classifications = np.zeros(n_samples, dtype=int)
        
        for i in range(n_samples):
            sample = X[i]
            severity = self._classify_single_sample(sample)
            classifications[i] = severity.value
        
        return classifications
    
    def _classify_single_sample(self, sample: np.ndarray) -> OutlierSeverity:
        """–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –æ–¥–Ω–æ–≥–æ –æ–±—Ä–∞–∑—Ü–∞."""
        # –î–ª—è –º–Ω–æ–≥–æ–º–µ—Ä–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞–∏—Ö—É–¥—à—É—é –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é
        max_severity = OutlierSeverity.NORMAL
        
        if self.config.bilateral:
            # –î–≤—É—Å—Ç–æ—Ä–æ–Ω–Ω—è—è –ø—Ä–æ–≤–µ—Ä–∫–∞
            beyond_outer = ((sample < self._outer_lower) | (sample > self._outer_upper))
            beyond_inner = ((sample < self._inner_lower) | (sample > self._inner_upper))
        else:
            # –¢–æ–ª—å–∫–æ –≤–µ—Ä—Ö–Ω–∏–µ –≥—Ä–∞–Ω–∏—Ü—ã
            beyond_outer = (sample > self._outer_upper)
            beyond_inner = (sample > self._inner_upper)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–π –ø—Ä–∏–∑–Ω–∞–∫
        if isinstance(beyond_outer, np.ndarray):
            if np.any(beyond_outer):
                max_severity = OutlierSeverity.EXTREME
            elif np.any(beyond_inner):
                max_severity = OutlierSeverity.MILD
        else:
            if beyond_outer:
                max_severity = OutlierSeverity.EXTREME
            elif beyond_inner:
                max_severity = OutlierSeverity.MILD
        
        return max_severity
    
    def _calculate_severity_scores(self, X: np.ndarray) -> np.ndarray:
        """
        –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —á–∏—Å–ª–æ–≤—ã—Ö –æ—Ü–µ–Ω–æ–∫ —Å–µ—Ä—å–µ–∑–Ω–æ—Å—Ç–∏.
        
        –û—Ü–µ–Ω–∫–∞ = max(0, —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ_–¥–æ_–±–ª–∏–∂–∞–π—à–µ–π_–≥—Ä–∞–Ω–∏—Ü—ã) / IQR
        """
        n_samples = len(X)
        severity_scores = np.zeros(n_samples)
        
        for i in range(n_samples):
            sample = X[i]
            
            if self.config.bilateral:
                # –†–∞—Å—Å—Ç–æ—è–Ω–∏—è –¥–æ –≤—Å–µ—Ö –≥—Ä–∞–Ω–∏—Ü
                dist_to_inner_lower = np.maximum(0, self._inner_lower - sample)
                dist_to_inner_upper = np.maximum(0, sample - self._inner_upper)
                
                # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –∑–∞ –ø—Ä–µ–¥–µ–ª—ã –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö –≥—Ä–∞–Ω–∏—Ü
                inner_violation = np.maximum(dist_to_inner_lower, dist_to_inner_upper)
            else:
                # –¢–æ–ª—å–∫–æ –≤–µ—Ä—Ö–Ω—è—è –≥—Ä–∞–Ω–∏—Ü–∞
                inner_violation = np.maximum(0, sample - self._inner_upper)
            
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –Ω–∞ IQR
            normalized_violation = inner_violation / self._iqr
            
            # –î–ª—è –º–Ω–æ–≥–æ–º–µ—Ä–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –±–µ—Ä–µ–º –º–∞–∫—Å–∏–º—É–º
            if isinstance(normalized_violation, np.ndarray) and len(normalized_violation) > 1:
                severity_scores[i] = np.max(normalized_violation)
            else:
                severity_scores[i] = float(normalized_violation)
        
        return severity_scores
    
    def get_statistics(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫ –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞."""
        if not self.fitted:
            return {"status": "not_fitted"}
        
        return {
            "fitted": True,
            "inner_fence_factor": self.config.inner_fence_factor,
            "outer_fence_factor": self.config.outer_fence_factor,
            "bilateral": self.config.bilateral,
            "classify_severity": self.config.classify_severity,
            "q1": self._q1.tolist() if isinstance(self._q1, np.ndarray) else self._q1,
            "q3": self._q3.tolist() if isinstance(self._q3, np.ndarray) else self._q3,
            "iqr": self._iqr.tolist() if isinstance(self._iqr, np.ndarray) else self._iqr,
            "inner_fences": {
                "lower": self._inner_lower.tolist() if isinstance(self._inner_lower, np.ndarray) else self._inner_lower,
                "upper": self._inner_upper.tolist() if isinstance(self._inner_upper, np.ndarray) else self._inner_upper
            },
            "outer_fences": {
                "lower": self._outer_lower.tolist() if isinstance(self._outer_lower, np.ndarray) else self._outer_lower,
                "upper": self._outer_upper.tolist() if isinstance(self._outer_upper, np.ndarray) else self._outer_upper
            }
        }
    
    def get_boxplot_data(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è boxplot."""
        if not self.fitted:
            raise ValueError("Detector must be fitted")
        
        return {
            "q1": self._q1.tolist() if isinstance(self._q1, np.ndarray) else self._q1,
            "q2_median": ((self._q1 + self._q3) / 2).tolist() if isinstance(self._q1, np.ndarray) else (self._q1 + self._q3) / 2,
            "q3": self._q3.tolist() if isinstance(self._q3, np.ndarray) else self._q3,
            "whiskers": {
                "lower": self._inner_lower.tolist() if isinstance(self._inner_lower, np.ndarray) else self._inner_lower,
                "upper": self._inner_upper.tolist() if isinstance(self._inner_upper, np.ndarray) else self._inner_upper
            },
            "outlier_thresholds": {
                "mild": {
                    "lower": self._inner_lower.tolist() if isinstance(self._inner_lower, np.ndarray) else self._inner_lower,
                    "upper": self._inner_upper.tolist() if isinstance(self._inner_upper, np.ndarray) else self._inner_upper
                },
                "extreme": {
                    "lower": self._outer_lower.tolist() if isinstance(self._outer_lower, np.ndarray) else self._outer_lower,
                    "upper": self._outer_upper.tolist() if isinstance(self._outer_upper, np.ndarray) else self._outer_upper
                }
            }
        }

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –¥–ª—è –∫—Ä–∏–ø—Ç–æ—Ç—Ä–µ–π–¥–∏–Ω–≥–∞
def create_crypto_tukey_detector(
    price_data: pd.DataFrame,
    features: Optional[List[str]] = None,
    inner_factor: float = 1.5,
    outer_factor: float = 3.0
) -> TukeyMethodDetector:
    """
    –°–æ–∑–¥–∞–Ω–∏–µ Tukey –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞ –¥–ª—è –∫—Ä–∏–ø—Ç–æ–¥–∞–Ω–Ω—ã—Ö.
    
    Args:
        price_data: DataFrame —Å —Ü–µ–Ω–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
        features: –°–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        inner_factor: –ú–Ω–æ–∂–∏—Ç–µ–ª—å –¥–ª—è –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö –≥—Ä–∞–Ω–∏—Ü
        outer_factor: –ú–Ω–æ–∂–∏—Ç–µ–ª—å –¥–ª—è –≤–Ω–µ—à–Ω–∏—Ö –≥—Ä–∞–Ω–∏—Ü
        
    Returns:
        –ù–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π TukeyMethodDetector
    """
    if features is None:
        features = ['close', 'volume']
        if 'returns' in price_data.columns:
            features.append('returns')
        if 'volatility' in price_data.columns:
            features.append('volatility')
    
    config = TukeyConfig(
        inner_fence_factor=inner_factor,
        outer_fence_factor=outer_factor,
        classify_severity=True,
        bilateral=True,
        quantile_method='linear'
    )
    
    detector = TukeyMethodDetector(config)
    detector.fit(price_data[features].dropna().values)
    
    return detector

def analyze_crypto_outliers(
    detector: TukeyMethodDetector,
    price_data: pd.DataFrame,
    features: List[str]
) -> Dict[str, Any]:
    """
    –ê–Ω–∞–ª–∏–∑ –≤—ã–±—Ä–æ—Å–æ–≤ –≤ –∫—Ä–∏–ø—Ç–æ–¥–∞–Ω–Ω—ã—Ö —Å –¥–µ—Ç–∞–ª—å–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π.
    
    Args:
        detector: –û–±—É—á–µ–Ω–Ω—ã–π TukeyMethodDetector
        price_data: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏
        features: –°–ø–∏—Å–æ–∫ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        
    Returns:
        Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞
    """
    data = price_data[features].dropna().values
    anomaly_labels, severity_scores = detector.detect(data)
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–∏–ø–∞–º –≤—ã–±—Ä–æ—Å–æ–≤
    n_normal = np.sum(anomaly_labels == 0)
    n_mild = np.sum(anomaly_labels == 1)
    n_extreme = np.sum(anomaly_labels == 2)
    n_total = len(anomaly_labels)
    
    # –ò–Ω–¥–µ–∫—Å—ã –≤—ã–±—Ä–æ—Å–æ–≤
    mild_indices = np.where(anomaly_labels == 1)[0]
    extreme_indices = np.where(anomaly_labels == 2)[0]
    
    return {
        "summary": {
            "total_samples": n_total,
            "normal": n_normal,
            "mild_outliers": n_mild,
            "extreme_outliers": n_extreme,
            "outlier_rate": (n_mild + n_extreme) / n_total
        },
        "outlier_indices": {
            "mild": mild_indices.tolist(),
            "extreme": extreme_indices.tolist()
        },
        "severity_stats": {
            "mean": np.mean(severity_scores),
            "std": np.std(severity_scores),
            "max": np.max(severity_scores),
            "percentiles": {
                "50": np.percentile(severity_scores, 50),
                "95": np.percentile(severity_scores, 95),
                "99": np.percentile(severity_scores, 99)
            }
        },
        "boxplot_data": detector.get_boxplot_data()
    }