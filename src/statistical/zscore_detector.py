"""
üìà Z-Score Anomaly Detector

Implements Z-score based anomaly detection for crypto trading data.
Z-score measures how many standard deviations away a data point is from the mean.

Context7 Features:
- Auto-scaling thresholds
- Real-time processing capability  
- Multi-dimensional anomaly detection
- Enterprise monitoring integration
"""

import numpy as np
import pandas as pd
from typing import Union, List, Tuple, Optional, Dict, Any
from dataclasses import dataclass
import structlog
from scipy import stats
import warnings

logger = structlog.get_logger(__name__)

@dataclass
class ZScoreConfig:
    """Configuration for Z-Score detector."""
    threshold: float = 3.0
    window_size: Optional[int] = None  # None = –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤—Å–µ –¥–∞–Ω–Ω—ã–µ
    rolling_window: bool = False  # True = —Å–∫–æ–ª—å–∑—è—â–µ–µ –æ–∫–Ω–æ
    min_samples: int = 30
    robust: bool = False  # True = –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–µ–¥–∏–∞–Ω—É –≤–º–µ—Å—Ç–æ —Å—Ä–µ–¥–Ω–µ–≥–æ
    bilateral: bool = True  # True = –¥–≤—É—Å—Ç–æ—Ä–æ–Ω–Ω—è—è –ø—Ä–æ–≤–µ—Ä–∫–∞
    auto_threshold: bool = False  # True = –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–æ—Ä–æ–≥–∞
    contamination: float = 0.1  # –û–∂–∏–¥–∞–µ–º–∞—è –¥–æ–ª—è –∞–Ω–æ–º–∞–ª–∏–π

class ZScoreDetector:
    """
    Z-Score Anomaly Detector –¥–ª—è –∫—Ä–∏–ø—Ç–æ—Ç—Ä–µ–π–¥–∏–Ω–≥–∞.
    
    –û–±–Ω–∞—Ä—É–∂–∏–≤–∞–µ—Ç –∞–Ω–æ–º–∞–ª–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ Z-score:
    z = (x - Œº) / œÉ
    
    Context7 Features:
    - Distributed processing support
    - Auto-scaling parameters
    - Real-time streaming capability
    - Enterprise monitoring
    """
    
    def __init__(self, config: Optional[ZScoreConfig] = None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Z-Score –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞.
        
        Args:
            config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞
        """
        self.config = config or ZScoreConfig()
        self.stats_cache = {}
        self.fitted = False
        self._mean = None
        self._std = None
        self._median = None
        self._mad = None  # Median Absolute Deviation
        
        logger.info(
            "ZScoreDetector initialized",
            threshold=self.config.threshold,
            robust=self.config.robust,
            auto_threshold=self.config.auto_threshold
        )
    
    def fit(self, X: Union[np.ndarray, pd.DataFrame, pd.Series]) -> 'ZScoreDetector':
        """
        –û–±—É—á–µ–Ω–∏–µ –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞ –Ω–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö.
        
        Args:
            X: –ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
            
        Returns:
            self: –û–±—É—á–µ–Ω–Ω—ã–π –¥–µ—Ç–µ–∫—Ç–æ—Ä
        """
        try:
            X = self._validate_input(X)
            
            if len(X) < self.config.min_samples:
                raise ValueError(
                    f"Insufficient samples: {len(X)} < {self.config.min_samples}"
                )
            
            # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            if self.config.robust:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–æ–±–∞—Å—Ç–Ω—ã–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
                self._median = np.median(X, axis=0)
                self._mad = np.median(np.abs(X - self._median), axis=0)
                # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É—é—â–∏–π —Ñ–∞–∫—Ç–æ—Ä –¥–ª—è MAD
                self._mad *= 1.4826  # –ö–æ–Ω—Å—Ç–∞–Ω—Ç–∞ –¥–ª—è –Ω–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
            else:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
                self._mean = np.mean(X, axis=0)
                self._std = np.std(X, axis=0, ddof=1)
            
            # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–æ—Ä–æ–≥–∞
            if self.config.auto_threshold:
                self._auto_tune_threshold(X)
            
            self.fitted = True
            
            logger.info(
                "ZScoreDetector fitted successfully",
                n_samples=len(X),
                n_features=X.shape[1] if X.ndim > 1 else 1,
                robust=self.config.robust,
                threshold=self.config.threshold
            )
            
            return self
            
        except Exception as e:
            logger.error("Failed to fit ZScoreDetector", error=str(e))
            raise
    
    def detect(self, X: Union[np.ndarray, pd.DataFrame, pd.Series]) -> Tuple[np.ndarray, np.ndarray]:
        """
        –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∞–Ω–æ–º–∞–ª–∏–π –≤ –¥–∞–Ω–Ω—ã—Ö.
        
        Args:
            X: –î–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            
        Returns:
            Tuple[np.ndarray, np.ndarray]: (anomaly_labels, anomaly_scores)
                anomaly_labels: 1 –¥–ª—è –∞–Ω–æ–º–∞–ª–∏–π, 0 –¥–ª—è –Ω–æ—Ä–º–∞–ª—å–Ω—ã—Ö —Ç–æ—á–µ–∫
                anomaly_scores: –ó–Ω–∞—á–µ–Ω–∏—è Z-score (—á–µ–º –±–æ–ª—å—à–µ, —Ç–µ–º –±–æ–ª–µ–µ –∞–Ω–æ–º–∞–ª—å–Ω–∞—è —Ç–æ—á–∫–∞)
        """
        if not self.fitted:
            raise ValueError("Detector must be fitted before detecting anomalies")
        
        try:
            X = self._validate_input(X)
            
            # –í—ã—á–∏—Å–ª—è–µ–º Z-scores
            if self.config.rolling_window and self.config.window_size:
                anomaly_labels, z_scores = self._detect_rolling(X)
            else:
                z_scores = self._calculate_zscore(X)
                anomaly_labels = self._classify_anomalies(z_scores)
            
            logger.debug(
                "Anomaly detection completed",
                n_samples=len(X),
                n_anomalies=np.sum(anomaly_labels),
                anomaly_rate=f"{np.mean(anomaly_labels):.3%}",
                max_score=np.max(np.abs(z_scores))
            )
            
            return anomaly_labels, np.abs(z_scores)
            
        except Exception as e:
            logger.error("Failed to detect anomalies", error=str(e))
            raise
    
    def detect_realtime(self, value: Union[float, np.ndarray]) -> Tuple[bool, float]:
        """
        Real-time –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∞–Ω–æ–º–∞–ª–∏–π –¥–ª—è –æ–¥–Ω–æ–π —Ç–æ—á–∫–∏ –¥–∞–Ω–Ω—ã—Ö.
        
        Args:
            value: –ó–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
            
        Returns:
            Tuple[bool, float]: (is_anomaly, z_score)
        """
        if not self.fitted:
            raise ValueError("Detector must be fitted before real-time detection")
        
        try:
            if isinstance(value, (int, float)):
                value = np.array([value])
            elif isinstance(value, list):
                value = np.array(value)
            
            z_score = self._calculate_zscore(value.reshape(1, -1))[0]
            is_anomaly = abs(z_score) > self.config.threshold
            
            if is_anomaly:
                logger.warning(
                    "Real-time anomaly detected",
                    value=value,
                    z_score=z_score,
                    threshold=self.config.threshold
                )
            
            return is_anomaly, abs(z_score)
            
        except Exception as e:
            logger.error("Failed real-time detection", error=str(e))
            raise
    
    def _validate_input(self, X: Union[np.ndarray, pd.DataFrame, pd.Series]) -> np.ndarray:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö."""
        if isinstance(X, pd.DataFrame):
            X = X.values
        elif isinstance(X, pd.Series):
            X = X.values.reshape(-1, 1)
        elif isinstance(X, list):
            X = np.array(X)
        
        if X.ndim == 1:
            X = X.reshape(-1, 1)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ NaN –∏ Inf
        if np.any(~np.isfinite(X)):
            warnings.warn("Input contains NaN or Inf values, removing them")
            X = X[np.isfinite(X).all(axis=1)]
        
        return X
    
    def _calculate_zscore(self, X: np.ndarray) -> np.ndarray:
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ Z-score."""
        if self.config.robust:
            # –†–æ–±–∞—Å—Ç–Ω—ã–π Z-score —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –º–µ–¥–∏–∞–Ω—ã –∏ MAD
            z_scores = (X - self._median) / self._mad
        else:
            # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π Z-score
            z_scores = (X - self._mean) / self._std
        
        # –î–ª—è –º–Ω–æ–≥–æ–º–µ—Ä–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏—Å–ø–æ–ª—å–∑—É–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π Z-score
        if z_scores.ndim > 1 and z_scores.shape[1] > 1:
            z_scores = np.max(np.abs(z_scores), axis=1)
        else:
            z_scores = z_scores.flatten()
        
        return z_scores
    
    def _classify_anomalies(self, z_scores: np.ndarray) -> np.ndarray:
        """–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∞–Ω–æ–º–∞–ª–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ Z-scores."""
        if self.config.bilateral:
            # –î–≤—É—Å—Ç–æ—Ä–æ–Ω–Ω—è—è –ø—Ä–æ–≤–µ—Ä–∫–∞
            return (np.abs(z_scores) > self.config.threshold).astype(int)
        else:
            # –û–¥–Ω–æ—Å—Ç–æ—Ä–æ–Ω–Ω—è—è –ø—Ä–æ–≤–µ—Ä–∫–∞ (—Ç–æ–ª—å–∫–æ –≤—ã—Å–æ–∫–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è)
            return (z_scores > self.config.threshold).astype(int)
    
    def _detect_rolling(self, X: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∞–Ω–æ–º–∞–ª–∏–π —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Å–∫–æ–ª—å–∑—è—â–µ–≥–æ –æ–∫–Ω–∞."""
        window_size = self.config.window_size
        n_samples = len(X)
        
        anomaly_labels = np.zeros(n_samples)
        z_scores = np.zeros(n_samples)
        
        for i in range(window_size, n_samples):
            window_data = X[i-window_size:i]
            
            if self.config.robust:
                window_median = np.median(window_data, axis=0)
                window_mad = np.median(np.abs(window_data - window_median), axis=0) * 1.4826
                z_score = (X[i] - window_median) / window_mad
            else:
                window_mean = np.mean(window_data, axis=0)
                window_std = np.std(window_data, axis=0, ddof=1)
                z_score = (X[i] - window_mean) / window_std
            
            # –î–ª—è –º–Ω–æ–≥–æ–º–µ—Ä–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            if isinstance(z_score, np.ndarray) and len(z_score) > 1:
                z_score = np.max(np.abs(z_score))
            
            z_scores[i] = z_score
            anomaly_labels[i] = int(abs(z_score) > self.config.threshold)
        
        return anomaly_labels, z_scores
    
    def _auto_tune_threshold(self, X: np.ndarray) -> None:
        """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–æ—Ä–æ–≥–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∞–Ω–Ω—ã—Ö."""
        # –í—ã—á–∏—Å–ª—è–µ–º –≤—Å–µ Z-scores –¥–ª—è –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö
        z_scores = self._calculate_zscore(X)
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç–∏–ª–∏ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø–æ—Ä–æ–≥–∞
        percentile = (1 - self.config.contamination) * 100
        threshold = np.percentile(np.abs(z_scores), percentile)
        
        # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ = 2.0 (—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –ø—Ä–∞–∫—Ç–∏–∫–∞)
        self.config.threshold = max(threshold, 2.0)
        
        logger.info(
            "Auto-tuned threshold",
            old_threshold=3.0,
            new_threshold=self.config.threshold,
            contamination=self.config.contamination
        )
    
    def get_statistics(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫ –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞."""
        if not self.fitted:
            return {"status": "not_fitted"}
        
        stats = {
            "fitted": True,
            "threshold": self.config.threshold,
            "robust": self.config.robust,
            "bilateral": self.config.bilateral,
            "min_samples": self.config.min_samples
        }
        
        if self.config.robust:
            stats.update({
                "median": self._median.tolist() if isinstance(self._median, np.ndarray) else self._median,
                "mad": self._mad.tolist() if isinstance(self._mad, np.ndarray) else self._mad
            })
        else:
            stats.update({
                "mean": self._mean.tolist() if isinstance(self._mean, np.ndarray) else self._mean,
                "std": self._std.tolist() if isinstance(self._std, np.ndarray) else self._std
            })
        
        return stats

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –¥–ª—è –∫—Ä–∏–ø—Ç–æ—Ç—Ä–µ–π–¥–∏–Ω–≥–∞
def create_crypto_zscore_detector(
    price_data: pd.DataFrame,
    threshold: float = 3.5,
    robust: bool = True
) -> ZScoreDetector:
    """
    –°–æ–∑–¥–∞–Ω–∏–µ Z-Score –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –¥–ª—è –∫—Ä–∏–ø—Ç–æ–¥–∞–Ω–Ω—ã—Ö.
    
    Args:
        price_data: DataFrame —Å —Ü–µ–Ω–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
        threshold: –ü–æ—Ä–æ–≥ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∞–Ω–æ–º–∞–ª–∏–π
        robust: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ä–æ–±–∞—Å—Ç–Ω—ã–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        
    Returns:
        –ù–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π ZScoreDetector
    """
    config = ZScoreConfig(
        threshold=threshold,
        robust=robust,
        auto_threshold=True,
        contamination=0.05,  # 5% –∞–Ω–æ–º–∞–ª–∏–π –æ–∂–∏–¥–∞–µ–º –≤ –∫—Ä–∏–ø—Ç–æ
        bilateral=True
    )
    
    detector = ZScoreDetector(config)
    detector.fit(price_data[['close', 'volume']].values)
    
    return detector